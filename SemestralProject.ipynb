{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042dee2e-2485-4634-888f-5e2e13f7d478",
   "metadata": {},
   "source": [
    "# Semestrální projekt, Využití Umělých Neuronových Sítí při kompresi dat\n",
    "- Student: Petr Ptáček, PTA0054\n",
    "- Vedoucí práce: Ing. Michal Vašinek Ph.D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c5a28-8fe6-4ec2-b5d5-8dcd77fb37fc",
   "metadata": {},
   "source": [
    "## Dataset Gutenberg\n",
    "- Data se skládají z 89 textových souborů, které dohromady tvoří knihu.\n",
    "- Těchto 89 souborů jsem si rozdělil v poměru 80 : 20 na trénovací a testovací sady."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14b80b-877b-4527-8a76-6892ada5d806",
   "metadata": {},
   "source": [
    "## Importy knihoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa77108-ac14-47f8-ae96-72223f94d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import time\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Pandas dataframes\n",
    "import pandas as pd\n",
    "# Numpy\n",
    "import numpy as np \n",
    "# Tensorflow 2.10.0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Graphing\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Packages for manipulation with images\n",
    "from PIL import Image\n",
    "\n",
    "#\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446a19b3-4e9b-4e78-abce-a970b959ab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gpu is ready to use\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bad2860-7bef-4180-babd-0e63e7333a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cpu_compiler', '/dt9/usr/bin/gcc'),\n",
       "             ('cuda_compute_capabilities',\n",
       "              ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']),\n",
       "             ('cuda_version', '11.2'),\n",
       "             ('cudnn_version', '8'),\n",
       "             ('is_cuda_build', True),\n",
       "             ('is_rocm_build', False),\n",
       "             ('is_tensorrt_build', True)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sysconfig.get_build_info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3d63d5-3cdf-4df4-92b6-6c0f5fb9d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level only to ERROR\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61255f-9ae8-4290-a51f-3ac22f515867",
   "metadata": {},
   "source": [
    "## Funkce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e088d8-e5db-4612-a57a-b56825614ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_alphabet(pattern: str) -> set():\\n     # list files in folder\\n    filenames = tf.data.Dataset.list_files(pattern,)\\n    alphabet = set()\\n    # For each file in folder\\n    for filename in filenames:\\n        # read whole file\\n        with open(filename.numpy(), mode=\"r\", encoding=\"ISO-8859-1\") as file:\\n            text = file.read()\\n             # insert the list to the set\\n            alphabet = alphabet.union(set(text))\\n            del text\\n\\n    return alphabet\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load alphabet of all files which meet the pattern.\n",
    "\"\"\"\n",
    "def load_alphabet(pattern: str) -> set():\n",
    "     # list files in folder\n",
    "    filenames = tf.data.Dataset.list_files(pattern,)\n",
    "    alphabet = set()\n",
    "    # For each file in folder\n",
    "    for filename in filenames:\n",
    "        # read whole file\n",
    "        with open(filename.numpy(), mode=\"r\", encoding=\"ISO-8859-1\") as file:\n",
    "            text = file.read()\n",
    "             # insert the list to the set\n",
    "            alphabet = alphabet.union(set(text))\n",
    "            del text\n",
    "\n",
    "    return alphabet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac998a2-ca47-41b2-9f21-001f91fbc1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_binary(pattern: str, shuffle: bool = False, seed:int = None, lengthOfSubstring: int = 3, portion: float = 0.5) -> ([],[]):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    # Get list of filenames from pattern\n",
    "    filenames = tf.data.Dataset.list_files(pattern, shuffle=shuffle, seed=seed)\n",
    "    filenames = [i.numpy() for i in filenames]\n",
    "    filenames = random.sample(filenames, int(len(filenames) * portion))\n",
    "    #print(filenames)\n",
    "    # Set initial file_index and position in file.\n",
    "    position_in_file = 0\n",
    "    file_index = 0\n",
    "    \n",
    "    print(f'Loading gutenberg dataset [{round( (file_index) / len(filenames) * 100, 1)} %]\\r', end=\"\")\n",
    "    # File Loop\n",
    "    while file_index < len(filenames):\n",
    "        # Open File\n",
    "        with open(filenames[file_index], mode=\"rb\") as file:\n",
    "            file.seek(position_in_file)\n",
    "            byte_x = [file.read(1) for i in range(0, lengthOfSubstring)] #file.read(lengthOfSubstring)\n",
    "            byte_y = [file.read(1)]\n",
    "            # Main read loop\n",
    "            while True:\n",
    "                # If end of file\n",
    "                if b'' in byte_x or b'' in byte_y:\n",
    "                    file_index += 1\n",
    "                    position_in_file = 0\n",
    "                    break\n",
    "                else:\n",
    "                    train_x.append(byte_x)\n",
    "                    train_y.append(byte_y)\n",
    "                    # Read like this: \"Hello world!\" -> (\"Hel\",\"l\"), (\"ell\",\"o\"), (\"llo\",\" \"), ...\n",
    "                    position_in_file += 1\n",
    "                    file.seek(position_in_file)\n",
    "                    byte_x = [file.read(1) for i in range(0, lengthOfSubstring)] #file.read(lengthOfSubstring)\n",
    "                    byte_y = [file.read(1)]\n",
    "        print(f'Loading gutenberg dataset [{round( (file_index) / len(filenames) * 100, 1)} %]\\r', end=\"\")\n",
    "                    \n",
    "    return train_x, train_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c71a86-3de9-4763-9fb6-9bd9e50ace7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_data(pattern: str, shuffle: bool = False, seed:int = None, lengthOfSubstring: int = 3, removeDuplicates:bool = False) -> ([],[]):\\n    # list files in folder\\n    filenames = tf.data.Dataset.list_files(pattern, shuffle=shuffle, seed=seed)\\n    data = []\\n    # For each file in folder\\n    for filename in filenames:\\n        # read whole file\\n        with open(filename.numpy(), mode=\"r\", encoding=\"ISO-8859-1\") as file:\\n            #print(filename.numpy())\\n            text = file.read()\\n\\n            for i in range(0, len(text)-lengthOfSubstring):\\n                #index = np.random.randint(low=0, high=len(text))\\n                index = i\\n                x = text[index:index + lengthOfSubstring]\\n                y = text[index + lengthOfSubstring]\\n                \\n                data.append((x, y))\\n            del text\\n        # Remove duplicates\\n        if removeDuplicates:\\n            data = list(dict.fromkeys(data))\\n    \\n    data_x = [x[0] for x in data]\\n    data_y = [x[1] for x in data]\\n    del data\\n    return np.array(data_x), np.array(data_y)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deprecated\n",
    "# Load data from files into train_x and train_y np arrays in format \"tex\" -> \"t\", \"ext\" -> \"u\", \"xtu\" -> \"r\", \"tur\" -> \"e\", ... \n",
    "\"\"\"\n",
    "def load_data(pattern: str, shuffle: bool = False, seed:int = None, lengthOfSubstring: int = 3, removeDuplicates:bool = False) -> ([],[]):\n",
    "    # list files in folder\n",
    "    filenames = tf.data.Dataset.list_files(pattern, shuffle=shuffle, seed=seed)\n",
    "    data = []\n",
    "    # For each file in folder\n",
    "    for filename in filenames:\n",
    "        # read whole file\n",
    "        with open(filename.numpy(), mode=\"r\", encoding=\"ISO-8859-1\") as file:\n",
    "            #print(filename.numpy())\n",
    "            text = file.read()\n",
    "\n",
    "            for i in range(0, len(text)-lengthOfSubstring):\n",
    "                #index = np.random.randint(low=0, high=len(text))\n",
    "                index = i\n",
    "                x = text[index:index + lengthOfSubstring]\n",
    "                y = text[index + lengthOfSubstring]\n",
    "                \n",
    "                data.append((x, y))\n",
    "            del text\n",
    "        # Remove duplicates\n",
    "        if removeDuplicates:\n",
    "            data = list(dict.fromkeys(data))\n",
    "    \n",
    "    data_x = [x[0] for x in data]\n",
    "    data_y = [x[1] for x in data]\n",
    "    del data\n",
    "    return np.array(data_x), np.array(data_y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6feddc0-ca6b-41b9-a412-eae984326f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef string_vectorizer(strng: str, alphabet: set() =string.ascii_lowercase) -> [[int]]:\\n    vector = [[0 if char != letter else 1 for char in alphabet] for letter in strng]\\n    return vector\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# String vectorizer function which hot encode each character into vector of 0/1 of size of alphabete\n",
    "\"\"\"\n",
    "def string_vectorizer(strng: str, alphabet: set() =string.ascii_lowercase) -> [[int]]:\n",
    "    vector = [[0 if char != letter else 1 for char in alphabet] for letter in strng]\n",
    "    return vector\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacb7dc6-7abc-4b97-8f79-730afc334429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alphabet(data_x, data_y):\n",
    "    alp = set()\n",
    "    for y in data_y:\n",
    "        for _y in y:\n",
    "            alp.add(_y)\n",
    "    for x in data_x:\n",
    "        for _x in x:\n",
    "            alp.add(_x)\n",
    "    return alp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "031fe1b8-7178-4ac6-9138-101fffc95017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7d0e1-be6e-4a09-9a69-34255228831e",
   "metadata": {},
   "source": [
    "## Třídy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd3475ca-5e86-44e4-b9b4-26d6a1127da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # From bytes to Int in range <0, 255>\n",
    "        batch_x = np.array([[int.from_bytes(x, \"big\") for x in batch_x[i]] for i in range(0, len(batch_x))])\n",
    "        batch_y = np.array([[int.from_bytes(y, \"big\") for y in batch_y[i]] for i in range(0, len(batch_y))])\n",
    "        \n",
    "        # From integers to vectors of size 256, one hot encoding\n",
    "        batch_x = np.array([tf.keras.utils.to_categorical(x, num_classes=256) for x in batch_x])\n",
    "        batch_y = np.array([tf.keras.utils.to_categorical(y, num_classes=256) for y in batch_y])\n",
    "        \n",
    "        # Return sizes are (batch_size, 3, 256), (batch_size, 1, 256)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c1a23-7786-4161-a994-38b0306cbd48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Načtení a zpracování dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8510d6d0-3ec8-470c-b737-47e2da73a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load alphabet of gutenberg dataset\n",
    "#start_time = time.time()\n",
    "#alphabet = load_alphabet(\"./data/gutenberg/train/*.txt\",)\n",
    "#alphabet = alphabet.union(load_alphabet(\"./data/gutenberg/test/*.txt\",))\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172097cb-05a5-4223-824b-e9b45188012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of alphabet\n",
    "#print(f\"Size of alphabet of gutenberg dataset: {len(alphabet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac5408b-636a-45e2-bd96-2aa51f12d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load train_x and train_y\n",
    "#start_time = time.time()\n",
    "#train_x, train_y = load_data(\"./data/gutenberg/train/*.txt\", seed=42, removeDuplicates=True)\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461a4996-5b91-499c-9fc0-5c4f97462ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x\n",
    "del train_y\n",
    "del test_x\n",
    "del test_y\n",
    "del val_x\n",
    "del val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f54779-99b4-488d-868d-8de9e2a31deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gutenberg dataset [100.0 %]\n",
      "Size of test dataset: 3351254 [13405272 B]\n"
     ]
    }
   ],
   "source": [
    "# Load test_x and test_y in bytes\n",
    "test_x, test_y = load_data_binary(\"./data/gutenberg/test/*-0.txt\", seed=42, lengthOfSubstring=3, portion=0.3)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "print(f\"\\nSize of test dataset: {len(test_y)} [{sys.getsizeof(test_x) + sys.getsizeof(test_y)} B]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06bbf387-506e-4eea-ab82-d0df9d6b5a92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gutenberg dataset [100.0 %]\n",
      "Size of train dataset: 22166977 [88668164 B]\n"
     ]
    }
   ],
   "source": [
    "# Load train_x and train_y in bytes\n",
    "train_x, train_y = load_data_binary(\"./data/gutenberg/train/*-0.txt\", seed=42, lengthOfSubstring=3, portion=0.5)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "print(f\"\\nSize of train dataset: {len(train_y)} [{sys.getsizeof(train_x) + sys.getsizeof(train_y)} B]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45cf5509-7776-45e1-a697-1c0a58767ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train set into - train and validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d311676e-5508-40a5-8425-0789760d9ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 69.49 %\n",
      "Validation data: 17.37 %\n",
      "Test data: 13.13 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {round(len(train_y) / (len(test_y) + len(train_y) + len(val_y)) * 100, 2) } %\")\n",
    "print(f\"Validation data: {round(len(val_y) / (len(test_y) + len(train_y) + len(val_y)) * 100, 2) } %\")\n",
    "print(f\"Test data: {round(len(test_y) / (len(test_y) + len(train_y) + len(val_y)) * 100, 2) } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4557ef4c-cb4c-4d9f-8814-a38e3ca41589",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_train = get_alphabet(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1f7867-f290-448e-9a25-9bd5d362c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_test = get_alphabet(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23365ef7-dacd-4b99-83f1-35530022fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 115)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabet_train), len(alphabet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee25a107-b593-41c7-93c5-112afd439c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = alphabet_test.union(alphabet_train)\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "958cf550-96bf-4e7c-9b81-319bfe17b80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(b'\\xbb', \"big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e5bbe-ac8e-4103-a674-56aeae26530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [[int.from_bytes(x, \"big\") for x in train_x[i]] for i in range(0, len(train_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70c0aa-09e8-46d4-a9ad-c116f521a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(train_x):\n",
    "    train_x[i] = [int.from_bytes(x, \"big\") for x in train_x[i]]\n",
    "    train_y[i] = [int.from_bytes(x, \"big\") for x in train_x[i]]\n",
    "    for j, _ in enumerate(train_x[i]):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b47cbe7-1e68-439a-a9bc-fa3998df3dd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical([1,123,156], num_classes=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff828916-55a2-4a5e-8480-d648c98b3860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'\\t',\n",
       " b'\\n',\n",
       " b'\\r',\n",
       " b' ',\n",
       " b'!',\n",
       " b'\"',\n",
       " b'#',\n",
       " b'$',\n",
       " b'%',\n",
       " b'&',\n",
       " b\"'\",\n",
       " b'(',\n",
       " b')',\n",
       " b'*',\n",
       " b'+',\n",
       " b',',\n",
       " b'-',\n",
       " b'.',\n",
       " b'/',\n",
       " b'0',\n",
       " b'1',\n",
       " b'2',\n",
       " b'3',\n",
       " b'4',\n",
       " b'5',\n",
       " b'6',\n",
       " b'7',\n",
       " b'8',\n",
       " b'9',\n",
       " b':',\n",
       " b';',\n",
       " b'<',\n",
       " b'=',\n",
       " b'>',\n",
       " b'?',\n",
       " b'@',\n",
       " b'A',\n",
       " b'B',\n",
       " b'C',\n",
       " b'D',\n",
       " b'E',\n",
       " b'F',\n",
       " b'G',\n",
       " b'H',\n",
       " b'I',\n",
       " b'J',\n",
       " b'K',\n",
       " b'L',\n",
       " b'M',\n",
       " b'N',\n",
       " b'O',\n",
       " b'P',\n",
       " b'Q',\n",
       " b'R',\n",
       " b'S',\n",
       " b'T',\n",
       " b'U',\n",
       " b'V',\n",
       " b'W',\n",
       " b'X',\n",
       " b'Y',\n",
       " b'Z',\n",
       " b'[',\n",
       " b'\\\\',\n",
       " b']',\n",
       " b'^',\n",
       " b'_',\n",
       " b'`',\n",
       " b'a',\n",
       " b'b',\n",
       " b'c',\n",
       " b'd',\n",
       " b'e',\n",
       " b'f',\n",
       " b'g',\n",
       " b'h',\n",
       " b'i',\n",
       " b'j',\n",
       " b'k',\n",
       " b'l',\n",
       " b'm',\n",
       " b'n',\n",
       " b'o',\n",
       " b'p',\n",
       " b'q',\n",
       " b'r',\n",
       " b's',\n",
       " b't',\n",
       " b'u',\n",
       " b'v',\n",
       " b'w',\n",
       " b'x',\n",
       " b'y',\n",
       " b'z',\n",
       " b'{',\n",
       " b'|',\n",
       " b'}',\n",
       " b'~',\n",
       " b'\\x80',\n",
       " b'\\x81',\n",
       " b'\\x82',\n",
       " b'\\x83',\n",
       " b'\\x84',\n",
       " b'\\x86',\n",
       " b'\\x88',\n",
       " b'\\x89',\n",
       " b'\\x8e',\n",
       " b'\\x8f',\n",
       " b'\\x91',\n",
       " b'\\x92',\n",
       " b'\\x93',\n",
       " b'\\x94',\n",
       " b'\\x95',\n",
       " b'\\x97',\n",
       " b'\\x98',\n",
       " b'\\x99',\n",
       " b'\\x9a',\n",
       " b'\\x9c',\n",
       " b'\\x9d',\n",
       " b'\\xa0',\n",
       " b'\\xa1',\n",
       " b'\\xa2',\n",
       " b'\\xa3',\n",
       " b'\\xa4',\n",
       " b'\\xa6',\n",
       " b'\\xa7',\n",
       " b'\\xa8',\n",
       " b'\\xa9',\n",
       " b'\\xaa',\n",
       " b'\\xab',\n",
       " b'\\xae',\n",
       " b'\\xaf',\n",
       " b'\\xb0',\n",
       " b'\\xb1',\n",
       " b'\\xb2',\n",
       " b'\\xb3',\n",
       " b'\\xb4',\n",
       " b'\\xb5',\n",
       " b'\\xb6',\n",
       " b'\\xb7',\n",
       " b'\\xb9',\n",
       " b'\\xbb',\n",
       " b'\\xbc',\n",
       " b'\\xbd',\n",
       " b'\\xbe',\n",
       " b'\\xbf',\n",
       " b'\\xc2',\n",
       " b'\\xc3',\n",
       " b'\\xc5',\n",
       " b'\\xcb',\n",
       " b'\\xce',\n",
       " b'\\xcf',\n",
       " b'\\xd7',\n",
       " b'\\xe1',\n",
       " b'\\xe2',\n",
       " b'\\xef'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b2bbb-cb5e-4c73-81ab-91b11a23305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at data\n",
    "for i, _ in enumerate(train_x):\n",
    "    print(f\"{train_x[i]} -> {train_y[i]}\")\n",
    "    if i == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67cec4c-7c3c-40fe-bcc5-3146a4fdb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data, Vectorize characters using one hot encoding\n",
    "train_x = np.array([string_vectorizer(x, alphabet) for x in train_x])\n",
    "train_y = np.array([string_vectorizer(x, alphabet) for x in train_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "117b1566-15e5-42f4-845f-c3afbdab03a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14cd07ac-505c-4f15-8070-ae377b7f6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.reshape((train_y.shape[0], len(alphabet)))\n",
    "val_y = val_y.reshape((val_y.shape[0], len(alphabet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9fd859f-0f1f-4810-a902-b5818db16ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape((train_x.shape[0], len(alphabet) * 3))\n",
    "val_x = val_x.reshape((val_x.shape[0], len(alphabet) * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa5a1bca-591c-4cb6-9387-5571e179456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size (X, y): (210756, 498), (210756, 166)\n",
      "Validation set size (X, y): (52690, 498), (52690, 166)\n"
     ]
    }
   ],
   "source": [
    "# Size of train and validation datasets\n",
    "print(f\"Train set size (X, y): {train_x.shape}, {train_y.shape}\")\n",
    "print(f\"Validation set size (X, y): {val_x.shape}, {val_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922b4d0-a2a4-4ad6-96e5-1f17013ed542",
   "metadata": {},
   "source": [
    "## Dense ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13dcf675-b933-4b3a-aa9e-5ab31ba35f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "inputShape = (3, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfe65482-9663-4845-9244-eed0b24fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model of dense ANN\n",
    "input_layer = tf.keras.Input(shape=inputShape)\n",
    "\n",
    "flatten_layer1 = tf.keras.layers.Flatten()(input_layer)\n",
    "\n",
    "dense_layer1 = tf.keras.layers.Dense(512, activation=\"relu\")(flatten_layer1)\n",
    "dense_layer1 = tf.keras.layers.Dropout(0.2)(dense_layer1)\n",
    "\n",
    "dense_layer2 = tf.keras.layers.Dense(128, activation=\"relu\")(dense_layer1)\n",
    "dense_layer2 = tf.keras.layers.Dropout(0.2)(dense_layer2)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(256, activation=\"softmax\",)(dense_layer2)\n",
    "output_layer = tf.keras.layers.Reshape((1, 256))(output_layer)\n",
    "\n",
    "# Create model\n",
    "dense_model = tf.keras.Model(input_layer, output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08710960-0c79-42ef-839d-96b72244cba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 3, 256)]          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               393728    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1, 256)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,416\n",
      "Trainable params: 492,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "# Optimizer - RMSprop\n",
    "# Loss - Binary Crossentropy\n",
    "# Metric - Binary Accuracy\n",
    "dense_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "650e1358-570b-41e7-a4ee-3bfc86c9ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138544/138544 [==============================] - 1071s 8ms/step - loss: 1.7861 - categorical_accuracy: 0.4707 - val_loss: 1.6839 - val_categorical_accuracy: 0.4884\n",
      "Epoch 2/10\n",
      "138544/138544 [==============================] - 1067s 8ms/step - loss: 1.7435 - categorical_accuracy: 0.4786 - val_loss: 1.6748 - val_categorical_accuracy: 0.4904\n",
      "Epoch 3/10\n",
      "138544/138544 [==============================] - 1078s 8ms/step - loss: 1.7391 - categorical_accuracy: 0.4796 - val_loss: 1.6728 - val_categorical_accuracy: 0.4889\n",
      "Epoch 4/10\n",
      "138544/138544 [==============================] - 1083s 8ms/step - loss: 1.7385 - categorical_accuracy: 0.4799 - val_loss: 1.6710 - val_categorical_accuracy: 0.4912\n",
      "Epoch 5/10\n",
      "138544/138544 [==============================] - 1081s 8ms/step - loss: 1.7391 - categorical_accuracy: 0.4800 - val_loss: 1.6725 - val_categorical_accuracy: 0.4910\n",
      "Epoch 6/10\n",
      "138544/138544 [==============================] - 1090s 8ms/step - loss: 1.7401 - categorical_accuracy: 0.4799 - val_loss: 1.6718 - val_categorical_accuracy: 0.4910\n",
      "Epoch 7/10\n",
      "138544/138544 [==============================] - 1088s 8ms/step - loss: 1.7413 - categorical_accuracy: 0.4798 - val_loss: 1.6732 - val_categorical_accuracy: 0.4905\n",
      "Epoch 8/10\n",
      "138544/138544 [==============================] - 1078s 8ms/step - loss: 1.7424 - categorical_accuracy: 0.4796 - val_loss: 1.6721 - val_categorical_accuracy: 0.4913\n",
      "Epoch 9/10\n",
      "138544/138544 [==============================] - 1087s 8ms/step - loss: 1.7440 - categorical_accuracy: 0.4795 - val_loss: 1.6740 - val_categorical_accuracy: 0.4900\n",
      "Epoch 10/10\n",
      "138544/138544 [==============================] - 1090s 8ms/step - loss: 1.7452 - categorical_accuracy: 0.4794 - val_loss: 1.6753 - val_categorical_accuracy: 0.4907\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoint for storing only best results\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights_dense_model.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "train_gen = DataGenerator(train_x, train_y, batch_size)\n",
    "val_gen = DataGenerator(val_x, val_y, batch_size)\n",
    "\n",
    "\n",
    "# Fit model.\n",
    "history_dense_model = dense_model.fit(train_gen, validation_data=val_gen, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67272619-936b-4aae-bf61-db03d45af1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history_dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c3ae45e-3cba-4642-b9fc-ad3b268a1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained weights and biases.\n",
    "dense_model.save('models/model_dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b4924-8030-4e7c-99e5-2a26556a4bec",
   "metadata": {},
   "source": [
    "## Recurrent ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "decec534-5a6c-4bb2-92e1-a382d1f53414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model of recurent ANN\n",
    "input_layer = tf.keras.Input(shape=inputShape)\n",
    "\n",
    "lstm_layer1 = tf.keras.layers.LSTM(64, activation=\"relu\", return_sequences=True)(input_layer)\n",
    "\n",
    "gru_layer1 = tf.keras.layers.GRU(64, activation=\"relu\", return_sequences=True)(lstm_layer1)\n",
    "\n",
    "flatten_layer1 = tf.keras.layers.Flatten()(gru_layer1)\n",
    "\n",
    "dense_layer1 = tf.keras.layers.Dense(512, activation=\"relu\")(flatten_layer1)\n",
    "\n",
    "dense_layer2 = tf.keras.layers.Dense(256, activation=\"relu\")(dense_layer1)\n",
    "dense_layer2 = tf.keras.layers.Dropout(0.3)(dense_layer2)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(256, activation=\"softmax\",)(dense_layer2)\n",
    "output_layer = tf.keras.layers.Reshape((1, 256))(output_layer)\n",
    "\n",
    "# Create model\n",
    "recurrent_model = tf.keras.Model(input_layer, output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de0d1bd9-4b62-4379-aeed-b1bd21066225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 3, 256)]          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 3, 64)             82176     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 3, 64)             24960     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               98816     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 1, 256)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,072\n",
      "Trainable params: 403,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "# Optimizer - RMSprop\n",
    "# Loss - Binary Crossentropy\n",
    "# Metric - Binary Accuracy\n",
    "recurrent_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "recurrent_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0eec6a-aae8-4937-9544-2a5b9a72016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17318/17318 [==============================] - 964s 56ms/step - loss: 1.8066 - categorical_accuracy: 0.4697 - val_loss: 1.7239 - val_categorical_accuracy: 0.4861\n",
      "Epoch 2/10\n",
      "17318/17318 [==============================] - 1101s 64ms/step - loss: 1.8023 - categorical_accuracy: 0.4725 - val_loss: 1.7616 - val_categorical_accuracy: 0.4760\n",
      "Epoch 3/10\n",
      "17318/17318 [==============================] - 1103s 64ms/step - loss: 1.8680 - categorical_accuracy: 0.4606 - val_loss: 1.8465 - val_categorical_accuracy: 0.4703\n",
      "Epoch 4/10\n",
      "17318/17318 [==============================] - 989s 57ms/step - loss: 1.9218 - categorical_accuracy: 0.4516 - val_loss: 1.8682 - val_categorical_accuracy: 0.4594\n",
      "Epoch 5/10\n",
      "17318/17318 [==============================] - 1008s 58ms/step - loss: 1.9845 - categorical_accuracy: 0.4408 - val_loss: 1.9245 - val_categorical_accuracy: 0.4521\n",
      "Epoch 6/10\n",
      "  760/17318 [>.............................] - ETA: 12:45 - loss: 2.0212 - categorical_accuracy: 0.4347"
     ]
    }
   ],
   "source": [
    "# Create checkpoint for storing only best results\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights_recurrent_model.best.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "\n",
    "train_gen = DataGenerator(train_x, train_y, batch_size)\n",
    "val_gen = DataGenerator(val_x, val_y, batch_size)\n",
    "\n",
    "\n",
    "# Fit model.\n",
    "history_recurrent_model = recurrent_model.fit(train_gen, validation_data=val_gen, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e2303-0233-4527-a3b8-b5a49d65b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history_recurrent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad64bd-d20b-4898-bf43-4929d5d333ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained weights and biases.\n",
    "recurrent_model.save('models/model_recurrent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
